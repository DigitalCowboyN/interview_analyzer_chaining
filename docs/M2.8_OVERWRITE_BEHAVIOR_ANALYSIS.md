# M2.8 Overwrite Behavior - Architectural Difference

**Date:** 2026-01-11
**Status:** Architectural Analysis
**Impact:** 4 of 15 analysis writer tests (27%)

---

## Executive Summary

M2.8's event-sourced architecture has a fundamental architectural difference from the dual-write implementation regarding how multiple analyses for the same sentence are handled.

**Old Behavior (Dual-Write):** Writing a new analysis **overwrites** the previous analysis in Neo4j.

**M2.8 Behavior (Event-Sourced):** Each `AnalysisGenerated` event is immutable. Multiple events create multiple versions.

**Failing Tests:** 4 tests that validate "overwrite" behavior are architecturally incompatible with event sourcing without additional logic.

---

## Architectural Difference

### Old Dual-Write Model

```
Pipeline → Neo4jAnalysisWriter.write_result()
    └──→ DELETE old Analysis relationships
    └──→ CREATE new Analysis relationships
    └──→ Result: Only latest analysis exists
```

**Characteristics:**
- **Destructive updates**: Old analysis is deleted
- **Single source of truth**: Neo4j contains only current state
- **No history**: Previous analyses are lost

### M2.8 Event-Sourced Model

```
Pipeline → emit AnalysisGenerated event
    └──→ EventStoreDB stores immutable event

Projection Service → AnalysisGeneratedHandler
    └──→ Processes each event
    └──→ Question: How to handle multiple events for same sentence?
```

**Characteristics:**
- **Immutable events**: Each AnalysisGenerated event is permanent
- **Event stream is truth**: EventStoreDB contains full history
- **Projections are derived**: Neo4j is rebuilt from events

---

## Failing Tests Analysis

### Test 1: test_single_value_dimensions_overwrite

**What it validates:**
- First analysis: `function_type="declarative"`
- Second analysis: `function_type="interrogative"`
- **Expected**: Only "interrogative" exists (overwrite)

**Why it fails:**
- Handler creates TWO Analysis nodes (one per event)
- Query matches FIRST Analysis node (still has "declarative")

**Business logic tested:**
- Re-running analysis on same sentence should **replace** old results
- User sees only latest AI-generated analysis

### Test 2: test_multi_value_dimensions_update_behavior

**What it validates:**
- First analysis: `overall_keywords=["original", "keyword", "analysis"]`
- Second analysis: `overall_keywords=["updated", "keywords"]`
- **Expected**: Only "updated" and "keywords" exist

**Why it fails:**
- Similar to Test 1 - multiple Analysis nodes

**Business logic tested:**
- Multi-value dimensions (keywords) are replaced, not merged
- Latest analysis completely replaces previous dimension sets

### Test 3: test_single_value_cardinality_enforcement

**What it validates:**
- Writes 8 keywords
- **Expected**: Only 6 stored (cardinality limit)
- Then writes analysis with different function_type
- **Expected**: Cardinality still 6, function updated

**Why it fails:**
- First part passes (cardinality limit works)
- Second part fails (overwrite issue)

**Business logic tested:**
- Cardinality limits enforced
- Re-analysis preserves limits while updating classifications

### Test 4: test_cardinality_limit_with_duplicates

**What it validates:**
- Writes keywords with duplicates: `["a", "b", "c", "a", "d", "e", "f", "g"]`
- **Expected**: 6 unique keywords, preserving order: `["a", "b", "c", "d", "e", "f"]`

**Why it fails:**
- May be related to duplicate handling OR overwrite behavior
- Need to examine test details

---

## Current Implementation Attempt

**What we tried:**
```python
# In AnalysisGeneratedHandler.apply()
# Delete old Analysis node
query_delete_old = """
MATCH (s:Sentence {aggregate_id: $aggregate_id})-[:HAS_ANALYSIS]->(old_a:Analysis)
DETACH DELETE old_a
"""
await tx.run(query_delete_old, aggregate_id=event.aggregate_id)

# Create new Analysis node
# ... create new Analysis
```

**Why it doesn't fully work:**
- Transaction timing issues
- Multiple events processed sequentially may create multiple Analysis nodes
- Queries in `_link_classification` may match wrong Analysis node

---

## Event Sourcing Philosophy

### Core Principle: Events Are Immutable

In event sourcing:
- **Events represent facts**: "AnalysisGenerated at 10:00 AM"
- **Facts don't change**: You can't "update" a fact
- **New facts supersede old ones**: "AnalysisGenerated at 10:05 AM" is newer

### Standard Approaches to "Updates"

#### Option A: Event Versioning
- First event: `AnalysisGenerated v1`
- Second event: `AnalysisSuperseded v2` (different event type)
- Projection keeps only latest version

#### Option B: Temporal Projections
- Store ALL Analysis nodes
- Mark older ones as `superseded: true`
- Queries filter to `superseded: false`

#### Option C: Single Projection Strategy
- Delete old Analysis BEFORE creating new one (what we tried)
- But requires careful transaction handling

---

## Questions to Answer

### Architectural Questions

1. **Should M2.8 allow multiple analyses per sentence?**
   - Pro: Full history, audit trail, A/B testing capability
   - Con: Complexity, storage overhead, query confusion

2. **Is "overwrite" the correct business requirement?**
   - When does re-analysis happen?
   - Do users need history of analysis versions?
   - Is this for error correction or model improvement tracking?

3. **Should events be designed differently?**
   - Current: `AnalysisGenerated` (can happen multiple times)
   - Alternative: `AnalysisSuperseded` (explicit replacement event)

### Test Design Questions

1. **Are these tests validating implementation details or business requirements?**
   - Implementation: "Neo4j has only one Analysis node"
   - Business: "User sees only latest analysis results"

2. **Can the business requirement be met differently in M2.8?**
   - Example: Query only the LATEST Analysis by timestamp
   - Tests verify "latest" logic, not "only one exists" logic

---

## Potential Solutions

### Solution 1: Temporal Analysis Nodes (RECOMMENDED)

**Approach:**
- Allow multiple Analysis nodes per Sentence
- Add `version`, `superseded_by`, `is_current` properties
- Queries filter to `is_current: true`

**Handler logic:**
```python
# Mark old analyses as superseded
query_mark_old = """
MATCH (s:Sentence {aggregate_id: $aggregate_id})-[:HAS_ANALYSIS]->(old_a:Analysis)
SET old_a.is_current = false, old_a.superseded_at = datetime()
"""

# Create new Analysis with is_current = true
query_create = """
CREATE (a:Analysis {
    analysis_id: $analysis_id,
    is_current: true,
    version: $version,
    ...
})
"""
```

**Test updates:**
- Change queries to filter `WHERE a.is_current = true`
- Validates business requirement (latest visible)
- Preserves audit history

**Pros:**
- Event-sourcing friendly (no deletion)
- Full audit trail
- Supports versioning
- Minimal query changes

**Cons:**
- Slightly more complex queries
- More storage (but negligible)

### Solution 2: Event Type Distinction

**Approach:**
- First analysis: `AnalysisGenerated`
- Subsequent analyses: `AnalysisSuperseded`
- Handler deletes old ONLY for `AnalysisSuperseded`

**Pros:**
- Explicit in event stream
- Clear intent

**Cons:**
- Requires event emitter changes
- More event types to maintain

### Solution 3: Delete-and-Replace (Current Attempt - Needs Fixing)

**Approach:**
- Continue with delete old + create new
- Fix transaction/query issues

**Missing fixes:**
- Ensure delete completes before create
- Ensure `_link_classification` queries use `analysis_id` not re-match
- Add retry logic for race conditions

**Pros:**
- Matches old behavior exactly
- Simpler projection

**Cons:**
- Loses audit history
- Not idiomatic event sourcing
- Race condition risks

### Solution 4: Test Refactoring

**Approach:**
- Accept that M2.8 has different behavior
- Refactor tests to validate business requirements, not implementation
- Add new tests for version history

**Changes:**
- Update queries to get LATEST Analysis (ORDER BY created_at DESC LIMIT 1)
- Add tests for "all versions exist"
- Remove "only one exists" assertions

**Pros:**
- Aligns tests with architecture
- Better coverage of new capabilities

**Cons:**
- Changes expected behavior
- Requires product decision

---

## Recommendation

**Recommend Solution 1: Temporal Analysis Nodes**

**Rationale:**
1. **Event-sourcing best practice**: Don't delete facts
2. **Business value**: Audit trail of analysis evolution
3. **Backward compatible**: Queries with `is_current: true` get latest
4. **Minimal changes**: Handler + test query updates
5. **Future-proof**: Enables version comparison, rollback

**Implementation:**
- Add `is_current: boolean` to Analysis nodes
- Handler marks old as `is_current: false`, creates new as `is_current: true`
- Update 4 failing tests to query `WHERE a.is_current = true`

**Estimated effort:** 2-3 hours

---

## Next Steps

1. **Decision Required**: Choose solution approach
2. **Product Input**: Confirm business requirement for analysis overwrite
3. **Implementation**: Apply chosen solution
4. **Testing**: Verify 4 failing tests pass
5. **Documentation**: Update architecture docs with chosen pattern

---

## Impact Assessment

**Without fix:**
- 11/15 tests passing (73%)
- Core functionality works
- Overwrite scenarios untested

**With Solution 1:**
- 15/15 tests passing (100%)
- Full audit capability
- Event-sourcing compliant
- Better long-term architecture

---

## Related Files

- Handler: `src/projections/handlers/sentence_handlers.py`
- Emitter: `src/pipeline_event_emitter.py`
- Tests: `tests/integration/test_neo4j_analysis_writer.py`
- Events: `src/events/sentence_events.py`
