# M2.8 Test Migration Plan

**Date:** 2026-01-11
**Status:** In Progress
**Current Phase:** Phase 1 - Critical Path Tests

---

## Executive Summary

Migration of test suite from M2.2 dual-write architecture to M2.8 event-sourced architecture where projection service is the SOLE writer to Neo4j.

**Test Architecture Change:**
- **M2.2 (Old):** Tests expect direct Neo4j writes from pipeline
- **M2.8 (New):** Tests must process events through projection service to validate Neo4j state

**Total Tests:** 758 tests
- ✅ **Passing:** 682 tests (90%)
- ❌ **Failing:** 76 tests (10%)

---

## Migration Phases

### Phase 1: Critical Path Tests ✅ IN PROGRESS

**Goal:** Update core storage and event emission tests to validate M2.8 architecture

**Completed:**
1. ✅ test_neo4j_map_storage.py (10 tests) - Core storage validation
2. ✅ test_dual_write_pipeline.py (10 passed, 2 skipped) - Event emission validation

**Status:** 682/758 tests passing (90%)

**Effort:** 4 hours completed

---

### Phase 2: End-to-End Integration Tests (CURRENT PHASE)

**Goal:** Update E2E tests to use projection service for Neo4j validation

**Scope:**
1. test_e2e_file_processing.py (~2 tests)
   - test_single_file_upload_with_dual_write
   - test_multiple_files_concurrent_processing

**Pattern:**
```python
# 1. Execute pipeline (emits events)
await orchestrator.execute()

# 2. Process events through projection service
await process_events_through_projection(event_store, interview_id, num_sentences)

# 3. Verify Neo4j state (written by projection service)
async with Neo4jConnectionManager.get_session() as session:
    result = await session.run("MATCH (s:Sentence) RETURN count(s)")
    assert result >= expected_count
```

**Estimated Effort:** 2-3 hours

---

### Phase 3: Analysis Writer Tests

**Goal:** Update analysis writer tests to validate projection service writes

**Scope:**
test_neo4j_analysis_writer.py (~35 tests)

**Key Changes:**
- Successful analyses → Event emission ONLY (no direct Neo4j write)
- Projection service writes analysis results from AnalysisGenerated events
- Error analyses → Still direct writes (no events for errors)

**Pattern:**
```python
# 1. Write analysis result (emits AnalysisGenerated event)
await writer.write_result(analysis_result)

# 2. Process AnalysisGenerated event through projection service
analysis_handler = AnalysisGeneratedHandler()
events = await event_store.read_stream(f"Sentence-{sentence_id}")
for event in events:
    if event.event_type == "AnalysisGenerated":
        await analysis_handler.handle(event)

# 3. Verify analysis nodes and relationships in Neo4j
async with Neo4jConnectionManager.get_session() as session:
    result = await session.run(
        "MATCH (s:Sentence)-[:HAS_ANALYSIS]->(a:Analysis) "
        "WHERE s.sentence_id = $sentence_id "
        "RETURN a",
        sentence_id=sentence_id
    )
    analysis_node = await result.single()
    assert analysis_node is not None
```

**Estimated Effort:** 4-6 hours

---

### Phase 4: DEPRECATED ARCHITECTURE TESTS ⚠️ SEPARATE WORK PACKAGE

**CRITICAL:** These tests use a **DEPRECATED data model** that predates M2.8 architecture.

**Scope:**
test_pipeline_neo4j_end_to_end.py (~5 tests)

**Problem:**
These tests validate the **OLD data model:**
```
Sentence → [:PART_OF_FILE] → SourceFile
Sentence.filename property
```

**Current M2.8 data model:**
```
Interview → [:HAS_SENTENCE] → Sentence
No filename property on Sentence
Sentence.sentence_id is UUID (not integer)
```

**Why These Are Different:**

1. **Architectural Mismatch:**
   - Tests expect: `MATCH (s:Sentence)-[:PART_OF_FILE]->(f:SourceFile)`
   - M2.8 reality: `MATCH (i:Interview)-[:HAS_SENTENCE]->(s:Sentence)`

2. **Property Mismatch:**
   - Tests expect: `s.filename = "interview_001.txt"`
   - M2.8 reality: No filename property on Sentence nodes

3. **ID Format Mismatch:**
   - Tests expect: Integer sentence_ids (0, 1, 2, ...)
   - M2.8 reality: UUID sentence_ids (deterministic uuid5)

**Recommendation:**
Mark these tests with `@pytest.mark.skip` and document as **PHASE 4 - ARCHITECTURE MIGRATION** work package.

**Tests to Skip:**
1. test_single_file_complete_pipeline
2. test_multiple_files_concurrent_processing
3. test_pipeline_error_recovery
4. test_pipeline_data_integrity_verification
5. test_run_pipeline_function_integration

**Effort to Rewrite:** 8-12 hours (complete architectural rewrite)

**Decision Required:**
- Option A: Skip and defer to Phase 4 (RECOMMENDED - separate work package)
- Option B: Rewrite now (delays deployment by 8-12 hours)

---

## Phase 4 Milestone: Architecture Migration ⚠️

**Name:** Legacy Data Model Migration
**Type:** Separate Work Package
**Priority:** Medium (not blocking M2.8 deployment)

### Scope

Complete rewrite of tests using deprecated SourceFile-based data model to use current Interview-based model.

**Files:**
1. test_pipeline_neo4j_end_to_end.py (~5 tests)
   - Test complete pipeline with deprecated data model
   - Need full architectural rewrite

**What Needs To Change:**

#### Old Pattern (Deprecated):
```python
# Create test file
test_file = input_dir / "interview_001.txt"

# Execute pipeline (writes to SourceFile model)
await orchestrator.execute()

# Verify using OLD model
result = await session.run(
    "MATCH (s:Sentence)-[:PART_OF_FILE]->(f:SourceFile) "
    "WHERE f.filename = $filename "
    "RETURN count(s) as sentence_count",
    filename="interview_001.txt"
)
```

#### New Pattern (M2.8):
```python
# Create test file
test_file = input_dir / "interview_001.txt"
interview_id = str(uuid.uuid4())

# Execute pipeline (emits events)
await orchestrator.execute()

# Process events through projection service
await process_events_through_projection(event_store, interview_id, num_sentences)

# Verify using NEW model
result = await session.run(
    "MATCH (i:Interview {interview_id: $interview_id})-[:HAS_SENTENCE]->(s:Sentence) "
    "RETURN count(s) as sentence_count",
    interview_id=interview_id
)
```

### Deliverables

1. Rewrite 5 tests for Interview-based data model
2. Remove all SourceFile-related assertions
3. Update to use UUID-based sentence_ids
4. Add projection service processing step

### Success Criteria

- All 5 tests pass with M2.8 architecture
- Tests validate Interview → Sentence relationships
- Tests use projection service for Neo4j validation
- No references to deprecated SourceFile model

### Estimated Effort

**Total:** 8-12 hours

**Breakdown:**
- Analysis of current tests: 1 hour
- Rewrite test 1 (single file pipeline): 2 hours
- Rewrite test 2 (multiple files concurrent): 2 hours
- Rewrite test 3 (error recovery): 2 hours
- Rewrite test 4 (data integrity): 2 hours
- Rewrite test 5 (run_pipeline function): 1 hour
- Testing and validation: 2 hours

### Dependencies

- ✅ Projection service handlers implemented
- ✅ M2.8 architecture deployed
- ✅ Interview-based data model in production

### Risks

- **Low Risk:** This is purely test migration, not production code
- **No Impact:** Deferring this work does not block M2.8 deployment
- **Technical Debt:** Acceptable - tests prove M2.8 works via Phase 1-3 tests

---

## Remaining Work (Current Focus)

### Phase 2: E2E Tests (NEXT)
- test_e2e_file_processing.py (~2 tests)
- Estimated: 2-3 hours

### Phase 3: Analysis Writer Tests (AFTER PHASE 2)
- test_neo4j_analysis_writer.py (~35 tests, target 10-15 critical tests)
- Estimated: 4-6 hours

### Total Remaining Effort (Phases 2-3): 6-9 hours

---

## Deployment Readiness Criteria

### Minimum (Phase 1-3 Complete):
- ✅ Core storage tests passing (Phase 1)
- ✅ Event emission tests passing (Phase 1)
- ⏳ E2E integration tests passing (Phase 2)
- ⏳ Critical analysis writer tests passing (Phase 3)
- **Target:** ~710+ tests passing (94%)

### Deferred (Phase 4):
- ⏸️ Legacy architecture tests (5 tests)
- **Reason:** Tests deprecated data model, separate work package
- **Tech Debt:** Tracked as Phase 4 milestone

---

## Test Pattern Reference

### M2.8 Test Pattern (Established)

```python
async def process_events_through_projection(
    event_store,
    interview_id: str,
    num_sentences: int,
):
    """
    Helper to process events through projection service handlers.
    Reusable across all M2.8 tests.
    """
    # 1. Process InterviewCreated event
    interview_handler = InterviewCreatedHandler()
    interview_stream = f"Interview-{interview_id}"
    interview_events = await event_store.read_stream(interview_stream)

    for event in interview_events:
        if event.event_type == "InterviewCreated":
            await interview_handler.handle(event)

    # 2. Process SentenceCreated events
    sentence_handler = SentenceCreatedHandler()

    for i in range(num_sentences):
        sentence_id = str(uuid.uuid5(uuid.NAMESPACE_DNS, f"{interview_id}:{i}"))
        sentence_stream = f"Sentence-{sentence_id}"
        sentence_events = await event_store.read_stream(sentence_stream)

        for event in sentence_events:
            if event.event_type == "SentenceCreated":
                await sentence_handler.handle(event)

# Standard M2.8 test structure
async def test_example(clean_event_store, clean_test_database):
    # 1. Emit events via pipeline
    await storage.write_entry(entry)

    # 2. Process events through projection service
    await process_events_through_projection(clean_event_store, interview_id, num_entries)

    # 3. Verify Neo4j state (written by projection service)
    read_entries = await storage.read_all_entries()
    assert len(read_entries) == expected_count
```

---

## Progress Tracking

### Completed (90%)
- ✅ Phase 1: Critical Path Tests (12 tests)
  - test_neo4j_map_storage.py (10 tests)
  - test_dual_write_pipeline.py (10 passed, 2 skipped)

### In Progress (Phase 2)
- ⏳ test_e2e_file_processing.py (2 tests)

### Pending
- ⏸️ Phase 3: test_neo4j_analysis_writer.py (10-15 critical tests)
- ⏸️ Phase 4: test_pipeline_neo4j_end_to_end.py (5 tests - SEPARATE WORK PACKAGE)

---

## Decision Log

### 2026-01-11: Phase 4 Separate Work Package
**Decision:** Defer test_pipeline_neo4j_end_to_end.py tests to Phase 4 milestone

**Rationale:**
1. Tests validate deprecated SourceFile-based data model
2. Complete architectural rewrite required (8-12 hours)
3. M2.8 architecture already validated by Phase 1-3 tests
4. Not blocking deployment
5. Better tracked as separate work package with dedicated effort

**Approved By:** User requirement - "Make sure to capture... We'll want to assess this as it's own work package"

**Impact:**
- Deployment timeline: No impact (not blocking)
- Test coverage: 94% with Phases 1-3 (acceptable)
- Technical debt: Clearly documented and tracked

---

## Success Metrics

### Phase 1-3 (Deployment Ready)
- Target: 710+ tests passing (94%)
- Core storage: 100% passing
- Event emission: 100% passing
- E2E integration: 100% passing
- Analysis writer: 80%+ passing (critical tests)

### Phase 4 (Future Work Package)
- Target: 5 additional tests passing
- Final coverage: 95%+ (715/758 tests)
- Zero references to deprecated data model

---

## Next Actions

1. ✅ Complete Phase 1 (DONE)
2. ⏳ **Start Phase 2:** Fix test_e2e_file_processing.py (2 tests)
3. **After Phase 2:** Fix critical test_neo4j_analysis_writer.py tests (10-15 tests)
4. **After Phase 3:** Run full test suite, verify ~710+ passing
5. **After deployment:** Schedule Phase 4 work package

---

## Phase 4 Work Package Template

**Milestone:** M2.8 Legacy Architecture Test Migration
**Type:** Technical Debt Reduction
**Priority:** P2 (Medium)
**Effort:** 8-12 hours
**Dependencies:** M2.8 deployed and stable

**Deliverables:**
- [ ] Rewrite test_single_file_complete_pipeline
- [ ] Rewrite test_multiple_files_concurrent_processing
- [ ] Rewrite test_pipeline_error_recovery
- [ ] Rewrite test_pipeline_data_integrity_verification
- [ ] Rewrite test_run_pipeline_function_integration
- [ ] Remove all SourceFile model references
- [ ] Update documentation

**Success Criteria:**
- All 5 tests passing
- Zero deprecated model references
- Full M2.8 architecture validation

---

**Last Updated:** 2026-01-11
**Next Review:** After Phase 3 completion
