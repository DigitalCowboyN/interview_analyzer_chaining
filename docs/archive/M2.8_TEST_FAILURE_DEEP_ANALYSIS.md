# M2.8 Test Failure Deep Analysis - Complete Assessment

**Date:** 2026-01-11
**Tests Analyzed:** 47 tests in `test_neo4j_analysis_writer.py`
**Status:** 11/15 M2.8-enabled tests passing (73%), 4 failing
**Analysis Outcome:** Architectural gap identified in event-first dual-write test pattern

---

## Executive Summary

The 4 failing tests validate **critical business logic** around re-analysis scenarios. They are NOT implementation details. The tests expose a **gap in how M2.8's event-first architecture handles sequential writes in test environments**.

### Key Finding

**Test 46 (project_limits_with_existing_relationships) PASSES** despite making two `write_result()` calls to the same sentence.

**Tests 8, 10, 17, 18 FAIL** when making two `write_result()` calls to the same sentence.

**The Difference:**
- **Test 46**: Uses direct Neo4j write (no event_emitter) → Works perfectly
- **Tests 8, 10, 17, 18**: Use event-first path (with event_emitter) → Projection replay doesn't properly handle sequential updates

**Conclusion:** The failing tests reveal that **M2.8's event-first dual-write doesn't yet properly support re-analysis scenarios in test environments**. The handler has delete logic, but test event replay may not be exercising it correctly.

---

## Test Categorization: All 47 Tests

### Tests Validating Re-Analysis / Overwrite Behavior

| Test # | Name | Status | What It Tests | Why Critical |
|--------|------|--------|---------------|--------------|
| 8 | `test_single_value_dimensions_overwrite` | ❌ FAIL | Second write replaces function_type | Re-analysis scenario |
| 10 | `test_multi_value_dimensions_update_behavior` | ❌ FAIL | Second write replaces all keywords | Re-analysis scenario |
| 17 | `test_single_value_cardinality_enforcement` | ❌ FAIL | Single-value has cardinality=1 | Re-analysis with limits |
| 18 | `test_cardinality_limit_with_duplicates` | ❌ FAIL | Dedup + limit on replacement | Re-analysis deduplication |
| **46** | `test_project_limits_with_existing_relationships` | ✅ **PASS** | **Second write respects limits** | **Same as 8,10,17,18** |

**Critical Insight:** Test 46 validates THE EXACT SAME business requirement as the 4 failing tests but uses the direct write path. This proves:
1. The business logic is correct and needed
2. The direct Neo4j write path works
3. The event-first path in tests doesn't properly support this yet

---

## Business Logic Validation

### When Re-Analysis Happens

**Not Yet in Production:**
- Pipeline currently writes each analysis once
- No built-in re-analysis flow exists
- But events are designed for it: `AnalysisRegenerated` event exists

**Future Scenarios:**
1. **Model Update**: New analysis model released, re-run all sentences
2. **Parameter Change**: User changes analysis settings, re-analyze
3. **Error Correction**: Manual re-trigger after failed analysis
4. **A/B Testing**: Compare old vs new analysis model

**User Expectation:**
- Latest analysis should be visible
- Previous analysis should be in audit history (event stream)
- User edits (is_edited=true) should be preserved

---

## Root Cause Analysis

### Why Test 46 Passes

```python
# Test 46 setup (line 2562-2574)
writer = Neo4jAnalysisWriter(project_id, interview_id)  # NO event_emitter!
await writer.initialize()

# First write
analysis_result1 = {"sentence_id": 0, "overall_keywords": ["keyword1", "keyword2"]}
await writer.write_result(analysis_result1)
# → Direct Neo4j write via MERGE query (line 195-200 of neo4j_analysis_writer.py)
# → Creates Analysis node

# Second write
analysis_result2 = {"sentence_id": 0, "overall_keywords": ["keyword3", "keyword4", "keyword5", "keyword6"]}
await writer.write_result(analysis_result2)
# → Same MERGE query finds existing Analysis
# → ON MATCH SET updates it
# → Works perfectly!
```

**MERGE query in neo4j_analysis_writer.py:**
```cypher
MATCH (s:Sentence {sentence_id: $sentence_id})<-[:HAS_SENTENCE]-(:Interview {interview_id: $interview_id})
MERGE (s)-[:HAS_ANALYSIS]->(a:Analysis)
ON CREATE SET a += $props
ON MATCH SET a += $props  // Second write hits this!
RETURN a
```

### Why Tests 8, 10, 17, 18 Fail

```python
# Tests 8, 10, 17, 18 setup
event_emitter = PipelineEventEmitter(clean_event_store)  # Event emitter!
writer = Neo4jAnalysisWriter(project_id, interview_id, event_emitter=event_emitter)
await writer.initialize()

# First write
analysis_result_1 = {"sentence_id": 0, "function_type": "declarative"}
await writer.write_result(analysis_result_1)
# → Event emitted to EventStoreDB (line 91-96 of neo4j_analysis_writer.py)
# → NO direct Neo4j write (line 145: "Projection service will handle")
# → Analysis ONLY in Event Store

# Second write
analysis_result_2 = {"sentence_id": 0, "function_type": "interrogative"}
await writer.write_result(analysis_result_2)
# → Second event emitted
# → Still NO Neo4j write

# Test then replays events through projection service
await process_events_through_projection(clean_event_store, interview_id, 1, process_analyses=True)
# → This SHOULD call AnalysisGeneratedHandler for BOTH events
# → Handler has delete logic:
#    - First event: Delete old (none), create Analysis#1 with "declarative"
#    - Second event: Delete Analysis#1, create Analysis#2 with "interrogative"
# → SHOULD result in only "interrogative" existing
# → But test sees "declarative" (first one)
```

**Why it fails:**
1. ~~Events not being read properly~~ (Unlikely - agent confirmed helper iterates all events)
2. ~~Delete query not working~~ (Unlikely - query syntax is correct)
3. **Most likely**: Transaction/session handling issue between sequential handler calls
4. **Or**: The helper processes events but doesn't commit between them, so deletes don't take effect

---

## Architectural Contradiction Identified

### The Dual-Write Paradox

**In M2.8 Dual-Write:**
- Pipeline writes to **EventStoreDB** (emits events)
- Pipeline writes to **Neo4j** (direct write for real-time UI)
- Projection service ALSO writes to **Neo4j** (from events)

**But the implementation is inconsistent:**

| Path | Event Emitted? | Direct Neo4j Write? | Projection Write? |
|------|---------------|---------------------|-------------------|
| **Error results** | ❌ No | ✅ Yes (immediate) | ❌ No |
| **Success results (with event_emitter)** | ✅ Yes | ❌ **No** (deferred to projection) | ✅ Yes (later) |
| **Success results (no event_emitter)** | ❌ No | ✅ Yes (immediate) | ❌ No |

**This creates a test architecture problem:**
- Tests with event_emitter must wait for projection replay
- Tests without event_emitter get immediate Neo4j writes
- Test 46 uses path 3 (works), Tests 8/10/17/18 use path 2 (fails)

---

## Event Model Analysis

### Available Event Types for Analysis

From `src/events/sentence_events.py`:

```python
class AnalysisGenerated(Event):
    """First analysis created for a sentence."""
    # Lines 93-106

class AnalysisRegenerated(Event):
    """Analysis regenerated (updated) for a sentence."""
    # Lines 108-119
    # Fields: reason, delta (optional)

class AnalysisOverridden(Event):
    """Analysis manually overridden by user."""
    # Lines 121-126
    # Fields: note, actor

class AnalysisCleared(Event):
    """Analysis cleared/deleted."""
    # Lines 128-132
```

**KEY: `AnalysisRegenerated` exists!** This is the proper event for re-analysis.

**Current problem:** Tests and code use `AnalysisGenerated` for both first analysis AND re-analysis. Should distinguish:
- First analysis → `AnalysisGenerated`
- Subsequent analyses → `AnalysisRegenerated`

---

## Handler Implementation Review

### AnalysisGeneratedHandler - Lines 144-156

```python
# Delete old Analysis node and create new one (overwrite behavior)
# M2.8: Multiple AnalysisGenerated events can occur for same sentence.
# Latest event should replace previous analysis.

# First, delete any existing Analysis nodes
query_delete_old = """
MATCH (s:Sentence {aggregate_id: $aggregate_id})-[:HAS_ANALYSIS]->(old_a:Analysis)
DETACH DELETE old_a
"""
result = await tx.run(query_delete_old, aggregate_id=event.aggregate_id)
summary = await result.consume()
if summary.counters.nodes_deleted > 0:
    logger.info(f"Deleted {summary.counters.nodes_deleted} old Analysis node(s)")
```

**The handler DOES implement delete-and-replace!**

**Verification needed:** Is this being called twice in tests? Check logs.

---

## Potential Issues in Test Helper

### process_events_through_projection - Lines 28-66

```python
async def process_events_through_projection(
    event_store,
    interview_id: str,
    num_sentences: int,  # This is the number of sentence STREAMS, not events!
    process_analyses: bool = True,
):
    # ... process Interview events ...

    for i in range(num_sentences):  # Loops once for sentence index 0
        sentence_id = str(uuid.uuid5(uuid.NAMESPACE_DNS, f"{interview_id}:{i}"))
        sentence_stream = f"Sentence-{sentence_id}"
        sentence_events = await event_store.read_stream(sentence_stream)

        for event in sentence_events:  # Should iterate ALL events in stream
            if event.event_type == "SentenceCreated":
                await sentence_handler.handle(event)
            elif event.event_type == "AnalysisGenerated" and analysis_handler:
                await analysis_handler.handle(event)  # Called TWICE for two events
```

**Question:** Are both AnalysisGenerated events actually in the stream?

**Debugging needed:**
1. Log how many events are in `sentence_events`
2. Log each call to `analysis_handler.handle(event)`
3. Verify both events have correct aggregate_id
4. Check if tx commits between handler calls

---

## Solutions Analysis

### Option 1: Fix Event-First Path (RECOMMENDED)

**Make the event-first path work like the direct path**

**Changes needed:**
1. **Distinguish event types:**
   - First write → `AnalysisGenerated`
   - Second+ write → `AnalysisRegenerated`
   - Update emitter to check if analysis exists (via event stream position)

2. **Ensure handler processes sequentially with commits:**
   - Test helper should commit after each event
   - Or use separate transactions per event

3. **Add logging to verify:**
   - Log each event processed
   - Log each Analysis deleted
   - Log each Analysis created

**Estimated effort:** 4-6 hours

**Pros:**
- Aligns with event sourcing semantics
- Uses proper event types
- Tests validate production behavior

**Cons:**
- Requires event emitter changes
- More complex test helper

---

### Option 2: Use Temporal Analysis Pattern (ALTERNATIVE)

**Allow multiple Analysis nodes, mark latest as `is_current`**

**Changes needed:**
1. Add `is_current: boolean` property to Analysis
2. Handler sets old to `is_current: false`, new to `is_current: true`
3. Update queries to filter `WHERE a.is_current = true`
4. Update 4 failing tests with this filter

**Estimated effort:** 2-3 hours

**Pros:**
- Event-sourcing best practice (no deletion)
- Full audit history preserved
- Simpler handler logic (no delete)

**Cons:**
- More nodes in graph (minimal impact)
- All queries need `is_current` filter

---

### Option 3: Make Tests Use Direct Path

**Change the 4 failing tests to NOT use event_emitter (like test 46)**

**Changes needed:**
1. Remove `event_emitter` parameter from writer initialization in 4 tests
2. Remove `process_events_through_projection` call
3. Tests now use direct Neo4j write (MERGE works)

**Estimated effort:** 30 minutes

**Pros:**
- Quick fix
- Tests pass immediately
- Matches test 46 pattern

**Cons:**
- **Tests no longer validate M2.8 event-first architecture**
- Doesn't test projection service behavior
- Defeats purpose of M2.8 validation

**Verdict:** ❌ **NOT RECOMMENDED** - defeats the purpose

---

### Option 4: Refactor to Projection-Only Tests

**Create new tests specifically for AnalysisGeneratedHandler unit tests**

**Changes needed:**
1. Create `tests/projections/test_analysis_generated_handler.py`
2. Unit test the handler directly:
   - Call handler with first event → verify Analysis created
   - Call handler with second event → verify old deleted, new created
3. Keep current tests but mark as "integration" tests
4. Or skip current 4 failing tests with `@pytest.mark.skip(reason="Event-first path TBD")`

**Estimated effort:** 2-3 hours

**Pros:**
- Unit tests are easier to debug
- Separates handler logic from event replay
- Can validate handler behavior independently

**Cons:**
- Still need integration tests eventually
- Doesn't fix the actual issue

---

## Critical Test Cases Matrix

| Scenario | Test 46 (Direct) | Tests 8/10/17/18 (Event) | Business Need |
|----------|------------------|--------------------------|---------------|
| First analysis | ✅ Creates Analysis | ✅ Creates Analysis | Required |
| Second analysis (same sentence) | ✅ Updates Analysis | ❌ **Broken** | **Required for re-analysis** |
| Edit protection | ✅ Preserves is_edited=true | Not tested | Required for user overrides |
| Cardinality limits | ✅ Enforces limits | ✅ (partial) | Required for data quality |
| Project overrides | ✅ Applies project limits | Not tested | Required for configuration |

**Gaps:**
- Event-first path doesn't support re-analysis (critical gap!)
- Edit protection not tested in event-first path
- Project overrides not tested in event-first path

---

## Equivalent Tests Search Results

### Tests Validating Similar Patterns

| Pattern | Test | Path | Status |
|---------|------|------|--------|
| Re-analysis with limits | Test 46 | Direct Neo4j | ✅ Pass |
| Re-analysis (single-value) | Test 8, 17 | Event-first | ❌ Fail |
| Re-analysis (multi-value) | Test 10 | Event-first | ❌ Fail |
| Deduplication | Test 18 | Event-first | ❌ Fail |
| Edit protection | Tests 20-23 | Direct Neo4j | ✅ Pass |
| First analysis | Tests 7, 9 | Both paths | ✅ Pass |

**No equivalent tests exist for event-first re-analysis path.**

---

## Recommendations

### Recommendation 1: Fix Event-First Path (Priority 1)

**Why:** M2.8 requires this path to work. Re-analysis is a legitimate business requirement.

**Steps:**
1. **Debug test helper:**
   - Add logging to `process_events_through_projection`
   - Verify both events are read
   - Verify handler called twice
   - Check transaction commits

2. **If handler called once:** Fix event stream reading
3. **If handler called twice but delete doesn't work:** Fix transaction handling
4. **If delete works but wrong Analysis returned:** Fix test query (add ORDER BY created_at DESC)

**Expected outcome:** All 15 tests pass

**Effort:** 4-6 hours

---

### Recommendation 2: Add Unit Tests for Handler (Priority 2)

**Why:** Easier to debug, validates handler logic independently

**Create:** `tests/projections/test_analysis_generated_handler.py`

**Test cases:**
```python
async def test_handler_deletes_old_analysis_on_second_event():
    # Create first event, process it → verify Analysis exists
    # Create second event, process it → verify old deleted, new exists
    # Assert only one Analysis exists

async def test_handler_preserves_audit_trail_in_events():
    # Verify both events remain in EventStoreDB
    # Even though only latest Analysis in Neo4j
```

**Effort:** 2-3 hours

---

### Recommendation 3: Document Architectural Decision (Priority 3)

**Why:** Clarify M2.8 design decisions

**Document:**
1. **Event-first dual-write semantics**
   - When to emit events
   - When to write directly
   - How they interact

2. **Re-analysis flow**
   - Use `AnalysisRegenerated` vs `AnalysisGenerated`
   - Handler behavior for each

3. **Test patterns**
   - When to use direct write in tests (unit tests, no events)
   - When to use event-first in tests (integration tests, validates full flow)

**Effort:** 1-2 hours

---

## Summary

### The 4 Failing Tests Are CRITICAL

They validate:
1. **Re-analysis scenarios** (user reruns analysis, model updates)
2. **Cardinality enforcement** (single-value = 1, keywords = 6)
3. **Deduplication** (duplicates in input are filtered)
4. **Replace semantics** (latest analysis wins, not merge)

### They Are NOT Implementation Details

Test 46 proves this - it tests THE SAME business logic and passes.

### The Issue Is In Event-First Test Infrastructure

- Handler has correct delete logic
- Event emitter works
- But sequential event replay in tests doesn't properly commit/isolate

### Fix Is Straightforward

Debug the test helper → ensure proper transaction handling → tests pass

### Alternative: Temporal Pattern

If delete-and-replace proves problematic, use `is_current` flag instead. Event-sourcing best practice, better audit trail.

---

## Next Actions

**Immediate (1-2 hours):**
1. Add detailed logging to `process_events_through_projection`
2. Run test 8 with logging
3. Verify handler called twice
4. Check if delete happens

**Short-term (4-6 hours):**
1. Fix transaction/commit handling in test helper OR
2. Implement temporal pattern with `is_current` flag
3. All 15 tests pass

**Medium-term (6-8 hours):**
1. Add unit tests for handler behavior
2. Document M2.8 event-first semantics
3. Add `AnalysisRegenerated` distinction in emitter

---

**Analysis Complete**
**Agent ID:** af9347d (if resuming for further investigation)
